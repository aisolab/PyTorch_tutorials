{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic concept of torchtext\n",
    "`Torchtext` takes a declarative approach to loading its data\n",
    "* reference: [A Comprehensive Introduction to Torchtext](http://mlexplained.com/2018/02/08/a-comprehensive-tutorial-to-torchtext/)\n",
    "\n",
    "![Alt text](https://i0.wp.com/mlexplained.com/wp-content/uploads/2018/02/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88-2018-02-07-10.32.59.png?resize=1024%2C481)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from mecab import MeCab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path().cwd() / 'data'\n",
    "nsmc = pd.read_csv(next(data_dir.iterdir()), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>애들 욕하지마라 지들은 뭐 그렇게 잘났나? 솔까 거기 나오는 귀여운 애들이 당신들보...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>여전히 반복되고 있는 80년대 한국 멜로 영화의 유치함.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>쉐임리스 스티브와 피오나가 손오공 부르마로 ㅋㅋㅋ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0점은 없나요?...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>제발 시즌2 ㅜㅜ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document  label\n",
       "0  애들 욕하지마라 지들은 뭐 그렇게 잘났나? 솔까 거기 나오는 귀여운 애들이 당신들보...      1\n",
       "1                    여전히 반복되고 있는 80년대 한국 멜로 영화의 유치함.      0\n",
       "2                        쉐임리스 스티브와 피오나가 손오공 부르마로 ㅋㅋㅋ      0\n",
       "3                                        0점은 없나요?...      0\n",
       "4                                          제발 시즌2 ㅜㅜ      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsmc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field\n",
    "\n",
    "sentence = Field(sequential=True, use_vocab=True, tokenize=MeCab().morphs, batch_first=True, fix_length=32)\n",
    "label = Field(sequential=False, use_vocab=False, batch_first=True, unk_token=None, pad_token=None, is_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> None\n",
      "<unk> None\n",
      "None None\n",
      "None None\n"
     ]
    }
   ],
   "source": [
    "print(sentence.pad_token, label.pad_token)\n",
    "print(sentence.unk_token, label.unk_token)\n",
    "print(sentence.eos_token, label.eos_token)\n",
    "print(sentence.init_token, label.init_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "애들 욕하지마라 지들은 뭐 그렇게 잘났나? 솔까 거기 나오는 귀여운 애들이 당신들보다 훨 낮다.\n"
     ]
    }
   ],
   "source": [
    "example_sentence = nsmc.iloc[0]['document']\n",
    "print(example_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['애', '들', '욕', '하', '지', '마', '라', '지', '들', '은', '뭐', '그렇게', '잘', '났', '나', '?', '솔', '까', '거기', '나오', '는', '귀여운', '애', '들', '이', '당신', '들', '보다', '훨', '낮', '다', '.']\n"
     ]
    }
   ],
   "source": [
    "list_of_tokens = sentence.tokenize(example_sentence)\n",
    "print(list_of_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab, build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_tokenized = nsmc['document'].apply(sentence.tokenize).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tokens = Counter(itertools.chain.from_iterable(list_of_tokenized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocab(counter=count_tokens, min_freq=10)\n",
    "sentence.vocab = vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['애', '들', '욕', '하', '지', '마', '라', '지', '들', '은', '뭐', '그렇게', '잘', '났', '나', '?', '솔', '까', '거기', '나오', '는', '귀여운', '애', '들', '이', '당신', '들', '보다', '훨', '낮', '다', '.']\n",
      "['<unk>', '<pad>', '.', '이', '는'] 8775\n",
      "tensor([[ 178,   20,  427,    8,   22,  289,  106,   22,   20,   12,   99,  623,\n",
      "           65,  683,   28,   26, 2402,  664,  833,  130,    4, 1161,  178,   20,\n",
      "            3,  753,   20,  105, 1278,  261,    6,    2]])\n"
     ]
    }
   ],
   "source": [
    "print(list_of_tokens)\n",
    "print(sentence.vocab.itos[:5], len(sentence.vocab))\n",
    "print(sentence.numericalize([list_of_tokens]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence.vocab = None # reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence.build_vocab(list_of_tokenized, min_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['애', '들', '욕', '하', '지', '마', '라', '지', '들', '은', '뭐', '그렇게', '잘', '났', '나', '?', '솔', '까', '거기', '나오', '는', '귀여운', '애', '들', '이', '당신', '들', '보다', '훨', '낮', '다', '.']\n",
      "['<unk>', '<pad>', '.', '이', '는'] 8775\n",
      "tensor([[ 178,   20,  427,    8,   22,  289,  106,   22,   20,   12,   99,  623,\n",
      "           65,  683,   28,   26, 2402,  664,  833,  130,    4, 1161,  178,   20,\n",
      "            3,  753,   20,  105, 1278,  261,    6,    2]])\n"
     ]
    }
   ],
   "source": [
    "print(list_of_tokens)\n",
    "print(sentence.vocab.itos[:5], len(sentence.vocab))\n",
    "print(sentence.numericalize([list_of_tokens]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Dataset, Example, TabularDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['애', '들', '욕', '하', '지', '마', '라', '지', '들', '은', '뭐', '그렇게', '잘', '났', '나', '?', '솔', '까', '거기', '나오', '는', '귀여운', '애', '들', '이', '당신', '들', '보다', '훨', '낮', '다', '.'] 1\n"
     ]
    }
   ],
   "source": [
    "# generate an Example\n",
    "example = Example.fromlist(nsmc.iloc[0].tolist(), fields=[('document', sentence), ('label', label)])\n",
    "print(example.document, example.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate list of Examples\n",
    "list_of_examples = [Example.fromlist(row.tolist(),\n",
    "                    fields=[('document', sentence), ('label', label)]) for _, row in nsmc.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<torchtext.data.example.Example object at 0x7efb6990b358>,\n",
      " <torchtext.data.example.Example object at 0x7efb6990b2e8>,\n",
      " <torchtext.data.example.Example object at 0x7efb6990b8d0>,\n",
      " <torchtext.data.example.Example object at 0x7efb6990b240>,\n",
      " <torchtext.data.example.Example object at 0x7efb6990b208>]\n",
      "['애', '들', '욕', '하', '지', '마', '라', '지', '들', '은', '뭐', '그렇게', '잘', '났', '나', '?', '솔', '까', '거기', '나오', '는', '귀여운', '애', '들', '이', '당신', '들', '보다', '훨', '낮', '다', '.'] 1\n"
     ]
    }
   ],
   "source": [
    "pprint(list_of_examples[:5])\n",
    "print(list_of_examples[0].document, list_of_examples[0].label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dataset\n",
    "dataset = Dataset(examples=list_of_examples, fields=[('document', sentence), ('label', label)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<torchtext.data.example.Example at 0x7efb6990b358>,\n",
       " <torchtext.data.example.Example at 0x7efb6990b2e8>,\n",
       " <torchtext.data.example.Example at 0x7efb6990b8d0>,\n",
       " <torchtext.data.example.Example at 0x7efb6990b240>,\n",
       " <torchtext.data.example.Example at 0x7efb6990b208>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.examples[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document': <torchtext.data.field.Field at 0x7efbc741bef0>,\n",
       " 'label': <torchtext.data.field.Field at 0x7efbc741be80>}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using TabularDataset\n",
    "sentence = Field(sequential=True, use_vocab=True, tokenize=MeCab().morphs, batch_first=True, fix_length=32)\n",
    "label = Field(sequential=False, use_vocab=False, batch_first=True, unk_token=None, pad_token=None, is_target=True)\n",
    "\n",
    "dataset = TabularDataset(path='data/train.txt', format='TSV', fields=[('document', sentence), ('label', label)],\n",
    "                         skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence.build_vocab(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = Iterator(dataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mb, y_mb = next(iter(iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[14141,     2,    17,   880,     6,   259,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1],\n",
      "        [   32,    43,     7,    67,   238,    10,   238,    14,    92,   628,\n",
      "             4,   457,     6,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1]]) tensor([0, 1])\n"
     ]
    }
   ],
   "source": [
    "print(x_mb, y_mb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
